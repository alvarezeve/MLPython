{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "quiet-sponsorship",
   "metadata": {},
   "source": [
    "# Breast Cancer Categorical Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ancient-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "boolean-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath  = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/breast-cancer.csv\"\n",
    "datafm = pd.read_csv(filepath\n",
    "            ,header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "earlier-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "datav = datafm.values #extract the values in array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dimensional-scholarship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'40-49'</td>\n",
       "      <td>'premeno'</td>\n",
       "      <td>'15-19'</td>\n",
       "      <td>'0-2'</td>\n",
       "      <td>'yes'</td>\n",
       "      <td>'3'</td>\n",
       "      <td>'right'</td>\n",
       "      <td>'left_up'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'recurrence-events'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'50-59'</td>\n",
       "      <td>'ge40'</td>\n",
       "      <td>'15-19'</td>\n",
       "      <td>'0-2'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'1'</td>\n",
       "      <td>'right'</td>\n",
       "      <td>'central'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'no-recurrence-events'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'50-59'</td>\n",
       "      <td>'ge40'</td>\n",
       "      <td>'35-39'</td>\n",
       "      <td>'0-2'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'2'</td>\n",
       "      <td>'left'</td>\n",
       "      <td>'left_low'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'recurrence-events'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'40-49'</td>\n",
       "      <td>'premeno'</td>\n",
       "      <td>'35-39'</td>\n",
       "      <td>'0-2'</td>\n",
       "      <td>'yes'</td>\n",
       "      <td>'3'</td>\n",
       "      <td>'right'</td>\n",
       "      <td>'left_low'</td>\n",
       "      <td>'yes'</td>\n",
       "      <td>'no-recurrence-events'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'40-49'</td>\n",
       "      <td>'premeno'</td>\n",
       "      <td>'30-34'</td>\n",
       "      <td>'3-5'</td>\n",
       "      <td>'yes'</td>\n",
       "      <td>'2'</td>\n",
       "      <td>'left'</td>\n",
       "      <td>'right_up'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'recurrence-events'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>'50-59'</td>\n",
       "      <td>'ge40'</td>\n",
       "      <td>'30-34'</td>\n",
       "      <td>'6-8'</td>\n",
       "      <td>'yes'</td>\n",
       "      <td>'2'</td>\n",
       "      <td>'left'</td>\n",
       "      <td>'left_low'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'no-recurrence-events'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>'50-59'</td>\n",
       "      <td>'premeno'</td>\n",
       "      <td>'25-29'</td>\n",
       "      <td>'3-5'</td>\n",
       "      <td>'yes'</td>\n",
       "      <td>'2'</td>\n",
       "      <td>'left'</td>\n",
       "      <td>'left_low'</td>\n",
       "      <td>'yes'</td>\n",
       "      <td>'no-recurrence-events'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>'30-39'</td>\n",
       "      <td>'premeno'</td>\n",
       "      <td>'30-34'</td>\n",
       "      <td>'6-8'</td>\n",
       "      <td>'yes'</td>\n",
       "      <td>'2'</td>\n",
       "      <td>'right'</td>\n",
       "      <td>'right_up'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'no-recurrence-events'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>'50-59'</td>\n",
       "      <td>'premeno'</td>\n",
       "      <td>'15-19'</td>\n",
       "      <td>'0-2'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'2'</td>\n",
       "      <td>'right'</td>\n",
       "      <td>'left_low'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'no-recurrence-events'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>'50-59'</td>\n",
       "      <td>'ge40'</td>\n",
       "      <td>'40-44'</td>\n",
       "      <td>'0-2'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'3'</td>\n",
       "      <td>'left'</td>\n",
       "      <td>'right_up'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'no-recurrence-events'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>286 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1        2      3      4    5        6           7  \\\n",
       "0    '40-49'  'premeno'  '15-19'  '0-2'  'yes'  '3'  'right'   'left_up'   \n",
       "1    '50-59'     'ge40'  '15-19'  '0-2'   'no'  '1'  'right'   'central'   \n",
       "2    '50-59'     'ge40'  '35-39'  '0-2'   'no'  '2'   'left'  'left_low'   \n",
       "3    '40-49'  'premeno'  '35-39'  '0-2'  'yes'  '3'  'right'  'left_low'   \n",
       "4    '40-49'  'premeno'  '30-34'  '3-5'  'yes'  '2'   'left'  'right_up'   \n",
       "..       ...        ...      ...    ...    ...  ...      ...         ...   \n",
       "281  '50-59'     'ge40'  '30-34'  '6-8'  'yes'  '2'   'left'  'left_low'   \n",
       "282  '50-59'  'premeno'  '25-29'  '3-5'  'yes'  '2'   'left'  'left_low'   \n",
       "283  '30-39'  'premeno'  '30-34'  '6-8'  'yes'  '2'  'right'  'right_up'   \n",
       "284  '50-59'  'premeno'  '15-19'  '0-2'   'no'  '2'  'right'  'left_low'   \n",
       "285  '50-59'     'ge40'  '40-44'  '0-2'   'no'  '3'   'left'  'right_up'   \n",
       "\n",
       "         8                       9  \n",
       "0     'no'     'recurrence-events'  \n",
       "1     'no'  'no-recurrence-events'  \n",
       "2     'no'     'recurrence-events'  \n",
       "3    'yes'  'no-recurrence-events'  \n",
       "4     'no'     'recurrence-events'  \n",
       "..     ...                     ...  \n",
       "281   'no'  'no-recurrence-events'  \n",
       "282  'yes'  'no-recurrence-events'  \n",
       "283   'no'  'no-recurrence-events'  \n",
       "284   'no'  'no-recurrence-events'  \n",
       "285   'no'  'no-recurrence-events'  \n",
       "\n",
       "[286 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "wound-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos entre las variables de entrada y salida del modelo\n",
    "X = datav[:, :-1] # todas las variables excepto la columna 9 de la recurrencia\n",
    "y = datav[:,-1] # la columan 9 sera la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "accurate-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "# damos formato a los arreglos para que sean de tipo string\n",
    "X = X.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "prompt-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reacomodamos el segundo arreglo para que sea separe cada entrada como un nuevo arreglo\n",
    "y = y.reshape((len(y), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-airplane",
   "metadata": {},
   "source": [
    "Una vez que hemos cargado los datos vamos a usarlos para crear y evaluar el modelo. \n",
    "Usaremos la función ```traint_test_split``` con el 67% de los datos para entrenar y 33% para evaluar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "similar-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "raising-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos entre datos para entrenar y datos para el test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,# los datos\n",
    "                                                    test_size=0.33, #el prorcentaje a sividir\n",
    "                                                    random_state=1 # randomizar los datos\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "auburn-departure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (191, 9) (191, 1)\n",
      "Test (95, 9) (95, 1)\n"
     ]
    }
   ],
   "source": [
    "# podemos ver como quedaron los datos\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-buddy",
   "metadata": {},
   "source": [
    " Tenemos 191 ejemplos para entrenar y 95 para la prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-street",
   "metadata": {},
   "source": [
    "Ahora que tenemos los datos vamos a codificarlos en valores numericos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "encouraging-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-command",
   "metadata": {},
   "source": [
    "La siguiente función toma como entradas los datos de prueba y de entrenamiento y los transforma usando un codificador ordinario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "increasing-israeli",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparamos los datos para poderlos usar en un modelo\n",
    "def prepare_inputs(X_train, X_test):\n",
    "    oe = OrdinalEncoder() # creo un codificador\n",
    "    oe.fit(X_train) #ajusto el codificador a los datos de entrenamiento \n",
    "    X_train_enc = oe.transform(X_train) # codifico los datos, esto ya es una arreglo numerico\n",
    "    X_test_enc = oe.transform(X_test) #codifico tambien los datos de prueba\n",
    "    return X_train_enc, X_test_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-tissue",
   "metadata": {},
   "source": [
    "También necesitamos preparar las variables de predicción. Como se trata en este caso de calsificar si el cancer es reincidente o no entonces es una clasificación binari. Mapearemos las dos opciones en valores de cero y uno. Como es una tarea de clasificación ordinaria el módulo de scikit-learn ya tiene implementada una función para codificarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "destroyed-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "clear-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare target\n",
    "def prepare_targets(y_train, y_test):\n",
    "    \n",
    "    return y_train_enc, y_test_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-cemetery",
   "metadata": {},
   "source": [
    "Ahora podemos llamar a las funciones para preparar nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "interested-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparamos\n",
    "X_train_enc, X_test_enc = prepare_inputs(X_train, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ecological-bouquet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare output data\n",
    "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-riding",
   "metadata": {},
   "source": [
    "### Modelo\n",
    "Podemos ahora definir el modelo, en este caso usaremos una red neuronal MLP (MultiLayer Perceptron) con una capa escondida con 10 nodos y un solo nodo en la salida que hará las clasificaciones binarias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "inner-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "proved-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos el modelo\n",
    "model = Sequential() # será un modelo sequencial\n",
    "# agregamos una capa al modelo de red que sea una capa densa\n",
    "model.add(Dense(10 #numero de nodos en la capa escondida\n",
    "                , input_dim=X_train_enc.shape[1] #le decimos la dimensión de los datos de entrada\n",
    "                , activation='relu' # definimos una función de activación rectificadora\n",
    "                , kernel_initializer='he_normal')) #iniciamos el kernel con una distribución\n",
    "# agregamos la capa final de salidaque también queremos que sea densa\n",
    "model.add(Dense(1, # número de nodos en la capa\n",
    "                activation='sigmoid')) #función de activación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-trouble",
   "metadata": {},
   "source": [
    "### Compilando el modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "european-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compilamos el modelo de keras\n",
    "model.compile(loss='binary_crossentropy' # función de pérdida\n",
    "              , optimizer='adam' #optimizador Adam(el mas común)\n",
    "              , metrics=['accuracy']) #?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-rachel",
   "metadata": {},
   "source": [
    "### Ajustando el modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "political-bristol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 - 0s - loss: 0.4182 - accuracy: 0.8272\n",
      "Epoch 2/100\n",
      "20/20 - 0s - loss: 0.4233 - accuracy: 0.8063\n",
      "Epoch 3/100\n",
      "20/20 - 0s - loss: 0.4173 - accuracy: 0.8168\n",
      "Epoch 4/100\n",
      "20/20 - 0s - loss: 0.4190 - accuracy: 0.8115\n",
      "Epoch 5/100\n",
      "20/20 - 0s - loss: 0.4189 - accuracy: 0.8220\n",
      "Epoch 6/100\n",
      "20/20 - 0s - loss: 0.4196 - accuracy: 0.8115\n",
      "Epoch 7/100\n",
      "20/20 - 0s - loss: 0.4173 - accuracy: 0.8010\n",
      "Epoch 8/100\n",
      "20/20 - 0s - loss: 0.4165 - accuracy: 0.8168\n",
      "Epoch 9/100\n",
      "20/20 - 0s - loss: 0.4177 - accuracy: 0.8115\n",
      "Epoch 10/100\n",
      "20/20 - 0s - loss: 0.4171 - accuracy: 0.8115\n",
      "Epoch 11/100\n",
      "20/20 - 0s - loss: 0.4186 - accuracy: 0.8115\n",
      "Epoch 12/100\n",
      "20/20 - 0s - loss: 0.4161 - accuracy: 0.8115\n",
      "Epoch 13/100\n",
      "20/20 - 0s - loss: 0.4170 - accuracy: 0.8115\n",
      "Epoch 14/100\n",
      "20/20 - 0s - loss: 0.4150 - accuracy: 0.8168\n",
      "Epoch 15/100\n",
      "20/20 - 0s - loss: 0.4203 - accuracy: 0.8168\n",
      "Epoch 16/100\n",
      "20/20 - 0s - loss: 0.4183 - accuracy: 0.8063\n",
      "Epoch 17/100\n",
      "20/20 - 0s - loss: 0.4158 - accuracy: 0.8115\n",
      "Epoch 18/100\n",
      "20/20 - 0s - loss: 0.4158 - accuracy: 0.8063\n",
      "Epoch 19/100\n",
      "20/20 - 0s - loss: 0.4146 - accuracy: 0.8063\n",
      "Epoch 20/100\n",
      "20/20 - 0s - loss: 0.4142 - accuracy: 0.8115\n",
      "Epoch 21/100\n",
      "20/20 - 0s - loss: 0.4138 - accuracy: 0.8115\n",
      "Epoch 22/100\n",
      "20/20 - 0s - loss: 0.4156 - accuracy: 0.8168\n",
      "Epoch 23/100\n",
      "20/20 - 0s - loss: 0.4134 - accuracy: 0.8063\n",
      "Epoch 24/100\n",
      "20/20 - 0s - loss: 0.4143 - accuracy: 0.8168\n",
      "Epoch 25/100\n",
      "20/20 - 0s - loss: 0.4132 - accuracy: 0.8063\n",
      "Epoch 26/100\n",
      "20/20 - 0s - loss: 0.4127 - accuracy: 0.8063\n",
      "Epoch 27/100\n",
      "20/20 - 0s - loss: 0.4143 - accuracy: 0.8168\n",
      "Epoch 28/100\n",
      "20/20 - 0s - loss: 0.4125 - accuracy: 0.8115\n",
      "Epoch 29/100\n",
      "20/20 - 0s - loss: 0.4202 - accuracy: 0.8168\n",
      "Epoch 30/100\n",
      "20/20 - 0s - loss: 0.4132 - accuracy: 0.8115\n",
      "Epoch 31/100\n",
      "20/20 - 0s - loss: 0.4127 - accuracy: 0.8115\n",
      "Epoch 32/100\n",
      "20/20 - 0s - loss: 0.4128 - accuracy: 0.8115\n",
      "Epoch 33/100\n",
      "20/20 - 0s - loss: 0.4111 - accuracy: 0.8168\n",
      "Epoch 34/100\n",
      "20/20 - 0s - loss: 0.4115 - accuracy: 0.8168\n",
      "Epoch 35/100\n",
      "20/20 - 0s - loss: 0.4132 - accuracy: 0.8010\n",
      "Epoch 36/100\n",
      "20/20 - 0s - loss: 0.4125 - accuracy: 0.8168\n",
      "Epoch 37/100\n",
      "20/20 - 0s - loss: 0.4129 - accuracy: 0.8115\n",
      "Epoch 38/100\n",
      "20/20 - 0s - loss: 0.4134 - accuracy: 0.8168\n",
      "Epoch 39/100\n",
      "20/20 - 0s - loss: 0.4118 - accuracy: 0.8168\n",
      "Epoch 40/100\n",
      "20/20 - 0s - loss: 0.4110 - accuracy: 0.8220\n",
      "Epoch 41/100\n",
      "20/20 - 0s - loss: 0.4113 - accuracy: 0.8168\n",
      "Epoch 42/100\n",
      "20/20 - 0s - loss: 0.4099 - accuracy: 0.8168\n",
      "Epoch 43/100\n",
      "20/20 - 0s - loss: 0.4100 - accuracy: 0.8168\n",
      "Epoch 44/100\n",
      "20/20 - 0s - loss: 0.4116 - accuracy: 0.8168\n",
      "Epoch 45/100\n",
      "20/20 - 0s - loss: 0.4101 - accuracy: 0.8168\n",
      "Epoch 46/100\n",
      "20/20 - 0s - loss: 0.4143 - accuracy: 0.8115\n",
      "Epoch 47/100\n",
      "20/20 - 0s - loss: 0.4098 - accuracy: 0.8168\n",
      "Epoch 48/100\n",
      "20/20 - 0s - loss: 0.4099 - accuracy: 0.8168\n",
      "Epoch 49/100\n",
      "20/20 - 0s - loss: 0.4114 - accuracy: 0.8168\n",
      "Epoch 50/100\n",
      "20/20 - 0s - loss: 0.4097 - accuracy: 0.8168\n",
      "Epoch 51/100\n",
      "20/20 - 0s - loss: 0.4100 - accuracy: 0.8115\n",
      "Epoch 52/100\n",
      "20/20 - 0s - loss: 0.4103 - accuracy: 0.8220\n",
      "Epoch 53/100\n",
      "20/20 - 0s - loss: 0.4148 - accuracy: 0.8168\n",
      "Epoch 54/100\n",
      "20/20 - 0s - loss: 0.4109 - accuracy: 0.8168\n",
      "Epoch 55/100\n",
      "20/20 - 0s - loss: 0.4087 - accuracy: 0.8168\n",
      "Epoch 56/100\n",
      "20/20 - 0s - loss: 0.4092 - accuracy: 0.8272\n",
      "Epoch 57/100\n",
      "20/20 - 0s - loss: 0.4090 - accuracy: 0.8272\n",
      "Epoch 58/100\n",
      "20/20 - 0s - loss: 0.4097 - accuracy: 0.8220\n",
      "Epoch 59/100\n",
      "20/20 - 0s - loss: 0.4084 - accuracy: 0.8168\n",
      "Epoch 60/100\n",
      "20/20 - 0s - loss: 0.4079 - accuracy: 0.8168\n",
      "Epoch 61/100\n",
      "20/20 - 0s - loss: 0.4115 - accuracy: 0.8115\n",
      "Epoch 62/100\n",
      "20/20 - 0s - loss: 0.4085 - accuracy: 0.8115\n",
      "Epoch 63/100\n",
      "20/20 - 0s - loss: 0.4072 - accuracy: 0.8168\n",
      "Epoch 64/100\n",
      "20/20 - 0s - loss: 0.4089 - accuracy: 0.8168\n",
      "Epoch 65/100\n",
      "20/20 - 0s - loss: 0.4076 - accuracy: 0.8063\n",
      "Epoch 66/100\n",
      "20/20 - 0s - loss: 0.4067 - accuracy: 0.8220\n",
      "Epoch 67/100\n",
      "20/20 - 0s - loss: 0.4067 - accuracy: 0.8220\n",
      "Epoch 68/100\n",
      "20/20 - 0s - loss: 0.4087 - accuracy: 0.8220\n",
      "Epoch 69/100\n",
      "20/20 - 0s - loss: 0.4066 - accuracy: 0.8220\n",
      "Epoch 70/100\n",
      "20/20 - 0s - loss: 0.4076 - accuracy: 0.8168\n",
      "Epoch 71/100\n",
      "20/20 - 0s - loss: 0.4064 - accuracy: 0.8220\n",
      "Epoch 72/100\n",
      "20/20 - 0s - loss: 0.4059 - accuracy: 0.8272\n",
      "Epoch 73/100\n",
      "20/20 - 0s - loss: 0.4057 - accuracy: 0.8220\n",
      "Epoch 74/100\n",
      "20/20 - 0s - loss: 0.4067 - accuracy: 0.8168\n",
      "Epoch 75/100\n",
      "20/20 - 0s - loss: 0.4075 - accuracy: 0.8115\n",
      "Epoch 76/100\n",
      "20/20 - 0s - loss: 0.4095 - accuracy: 0.8220\n",
      "Epoch 77/100\n",
      "20/20 - 0s - loss: 0.4099 - accuracy: 0.8220\n",
      "Epoch 78/100\n",
      "20/20 - 0s - loss: 0.4107 - accuracy: 0.8115\n",
      "Epoch 79/100\n",
      "20/20 - 0s - loss: 0.4083 - accuracy: 0.8220\n",
      "Epoch 80/100\n",
      "20/20 - 0s - loss: 0.4067 - accuracy: 0.8168\n",
      "Epoch 81/100\n",
      "20/20 - 0s - loss: 0.4082 - accuracy: 0.8115\n",
      "Epoch 82/100\n",
      "20/20 - 0s - loss: 0.4077 - accuracy: 0.8115\n",
      "Epoch 83/100\n",
      "20/20 - 0s - loss: 0.4072 - accuracy: 0.8063\n",
      "Epoch 84/100\n",
      "20/20 - 0s - loss: 0.4045 - accuracy: 0.8115\n",
      "Epoch 85/100\n",
      "20/20 - 0s - loss: 0.4052 - accuracy: 0.8220\n",
      "Epoch 86/100\n",
      "20/20 - 0s - loss: 0.4057 - accuracy: 0.8220\n",
      "Epoch 87/100\n",
      "20/20 - 0s - loss: 0.4051 - accuracy: 0.8115\n",
      "Epoch 88/100\n",
      "20/20 - 0s - loss: 0.4070 - accuracy: 0.8377\n",
      "Epoch 89/100\n",
      "20/20 - 0s - loss: 0.4068 - accuracy: 0.8220\n",
      "Epoch 90/100\n",
      "20/20 - 0s - loss: 0.4065 - accuracy: 0.8272\n",
      "Epoch 91/100\n",
      "20/20 - 0s - loss: 0.4064 - accuracy: 0.8168\n",
      "Epoch 92/100\n",
      "20/20 - 0s - loss: 0.4045 - accuracy: 0.8063\n",
      "Epoch 93/100\n",
      "20/20 - 0s - loss: 0.4041 - accuracy: 0.8272\n",
      "Epoch 94/100\n",
      "20/20 - 0s - loss: 0.4046 - accuracy: 0.8220\n",
      "Epoch 95/100\n",
      "20/20 - 0s - loss: 0.4109 - accuracy: 0.8220\n",
      "Epoch 96/100\n",
      "20/20 - 0s - loss: 0.4058 - accuracy: 0.8063\n",
      "Epoch 97/100\n",
      "20/20 - 0s - loss: 0.4066 - accuracy: 0.8220\n",
      "Epoch 98/100\n",
      "20/20 - 0s - loss: 0.4051 - accuracy: 0.8168\n",
      "Epoch 99/100\n",
      "20/20 - 0s - loss: 0.4070 - accuracy: 0.8272\n",
      "Epoch 100/100\n",
      "20/20 - 0s - loss: 0.4077 - accuracy: 0.8168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f245021c2e0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ajustamos el modelo a los datos tratados\n",
    "model.fit(X_train_enc #los datos codificados de entrenamiento\n",
    "          , y_train_enc #los datos de respuesta codificados de entrenamiento\n",
    "          , epochs=100 \n",
    "          , batch_size=10 \n",
    "          , verbose=2) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-budget",
   "metadata": {},
   "source": [
    "### Evaluando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "plain-frank",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.58\n"
     ]
    }
   ],
   "source": [
    "# evaluamos el modelo\n",
    "_, accuracy = model.evaluate(X_test_enc #los datos para la prueba\n",
    "                             , y_test_enc # datos objetivo para la prueba \n",
    "                             , verbose=0)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-invite",
   "metadata": {},
   "source": [
    "Note: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n",
    "\n",
    "In this case, we can see that the model achieved an accuracy of about 70% on the test dataset.\n",
    "\n",
    "Not bad, given that an ordinal relationship only exists for some of the input variables, and for those where it does, it was not honored in the encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-expense",
   "metadata": {},
   "source": [
    "# How to One Hot Encode Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-scheme",
   "metadata": {},
   "source": [
    "El codificador One Hot es usado para datos que no tienen relación entre sus categorías. \n",
    "El método trata de representar cada variable como un vector de ceos y unos, el cual tiene un uno en la categoría que represente la caracterítica. Así cada variable en los datos se va a reemplazar por un vector. \n",
    "La librería de scikit ya tiene un método para codificar los datos llamado OneHotEnconder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "generic-validity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare input data\n",
    "\n",
    "def prepare_inputs(X_train, X_test):\n",
    "    ohe = OneHotEncoder() # creamos el codificador\n",
    "    ohe.fit(X_train) # lo ajustamos a los datos de entrenamiento\n",
    "    X_train_enc = ohe.transform(X_train) #transformamos los datos de entrenamiento\n",
    "    X_test_enc = ohe.transform(X_test) # transformamos los datos de prueba\n",
    "    return X_train_enc, X_test_enc # los regresamos para que podamos usarlos en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "instrumental-bouquet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "focused-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of one hot encoding for a neural network\n",
    "\n",
    "\n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "    # load the dataset as a pandas DataFrame\n",
    "    data = read_csv(filename, header=None)\n",
    "    # retrieve numpy array\n",
    "    dataset = data.values\n",
    "    # split into input (X) and output (y) variables\n",
    "    X = dataset[:, :-1]\n",
    "    y = dataset[:,-1]\n",
    "    # format all fields as string\n",
    "    X = X.astype(str)\n",
    "    # reshape target to be a 2d array\n",
    "    y = y.reshape((len(y), 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "indoor-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare input data\n",
    "# despues de haber separado los datos lo que sigue es \n",
    "def prepare_inputs(X_train, X_test):\n",
    "    ohe = OneHotEncoder() #creamos el codificador\n",
    "    ohe.fit(X_train) #entrenamos el codififcador\n",
    "    X_train_enc = ohe.transform(X_train) # transformamos los datos de entrenamiento\n",
    "    X_test_enc = ohe.transform(X_test) #Transformamos los datos de prueba\n",
    "    return X_train_enc, X_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "proper-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare target\n",
    "# una vez que los datos estan codificados los vamos a codificar los datos de salida\n",
    "def prepare_targets(y_train, y_test):\n",
    "    le = LabelEncoder() #usamos ahora un label encoder que asigna a cada carcater un entero\n",
    "    le.fit(y_train) #ajustamos los datos, veamos que en este caso no es necesario entrenar el codificador\n",
    "    y_train_enc = le.transform(y_train) #transformamos los datos\n",
    "    y_test_enc = le.transform(y_test)\n",
    "    return y_train_enc, y_test_enc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "proprietary-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "X, y = load_dataset('breast-cancer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cloudy-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "exotic-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare input data\n",
    "#codificando los datos en entrada\n",
    "X_train_enc, X_test_enc = prepare_inputs(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "prepared-reducing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evelynalvarez/.julia/conda/3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# prepare output data\n",
    "#codificando los datos de salida\n",
    "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "defensive-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the  model\n",
    "model = Sequential() #modelo sequencial\n",
    "# agregamos una capa densa\n",
    "model.add(Dense(10 # nodos\n",
    "                , input_dim=X_train_enc.shape[1] #de dimensión igual a la de los datos de entrenamiento de entrada\n",
    "                , activation='relu' #usando una función activadora  rectificadora lineal\n",
    "                , kernel_initializer='he_normal')) \n",
    "# agregamos una capa densa que será la de salida\n",
    "model.add(Dense(1, #1 solo nodo\n",
    "                activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "amber-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "obvious-extent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/130\n",
      "20/20 - 0s - loss: 0.3500 - accuracy: 0.8691\n",
      "Epoch 2/130\n",
      "20/20 - 0s - loss: 0.3477 - accuracy: 0.8691\n",
      "Epoch 3/130\n",
      "20/20 - 0s - loss: 0.3457 - accuracy: 0.8691\n",
      "Epoch 4/130\n",
      "20/20 - 0s - loss: 0.3446 - accuracy: 0.8639\n",
      "Epoch 5/130\n",
      "20/20 - 0s - loss: 0.3426 - accuracy: 0.8639\n",
      "Epoch 6/130\n",
      "20/20 - 0s - loss: 0.3403 - accuracy: 0.8796\n",
      "Epoch 7/130\n",
      "20/20 - 0s - loss: 0.3384 - accuracy: 0.8743\n",
      "Epoch 8/130\n",
      "20/20 - 0s - loss: 0.3371 - accuracy: 0.8743\n",
      "Epoch 9/130\n",
      "20/20 - 0s - loss: 0.3354 - accuracy: 0.8796\n",
      "Epoch 10/130\n",
      "20/20 - 0s - loss: 0.3337 - accuracy: 0.8743\n",
      "Epoch 11/130\n",
      "20/20 - 0s - loss: 0.3323 - accuracy: 0.8796\n",
      "Epoch 12/130\n",
      "20/20 - 0s - loss: 0.3324 - accuracy: 0.8691\n",
      "Epoch 13/130\n",
      "20/20 - 0s - loss: 0.3313 - accuracy: 0.8743\n",
      "Epoch 14/130\n",
      "20/20 - 0s - loss: 0.3266 - accuracy: 0.8796\n",
      "Epoch 15/130\n",
      "20/20 - 0s - loss: 0.3253 - accuracy: 0.8796\n",
      "Epoch 16/130\n",
      "20/20 - 0s - loss: 0.3232 - accuracy: 0.8743\n",
      "Epoch 17/130\n",
      "20/20 - 0s - loss: 0.3216 - accuracy: 0.8796\n",
      "Epoch 18/130\n",
      "20/20 - 0s - loss: 0.3203 - accuracy: 0.8796\n",
      "Epoch 19/130\n",
      "20/20 - 0s - loss: 0.3179 - accuracy: 0.8796\n",
      "Epoch 20/130\n",
      "20/20 - 0s - loss: 0.3164 - accuracy: 0.8848\n",
      "Epoch 21/130\n",
      "20/20 - 0s - loss: 0.3144 - accuracy: 0.8901\n",
      "Epoch 22/130\n",
      "20/20 - 0s - loss: 0.3131 - accuracy: 0.8901\n",
      "Epoch 23/130\n",
      "20/20 - 0s - loss: 0.3112 - accuracy: 0.8901\n",
      "Epoch 24/130\n",
      "20/20 - 0s - loss: 0.3112 - accuracy: 0.8901\n",
      "Epoch 25/130\n",
      "20/20 - 0s - loss: 0.3082 - accuracy: 0.8901\n",
      "Epoch 26/130\n",
      "20/20 - 0s - loss: 0.3073 - accuracy: 0.8901\n",
      "Epoch 27/130\n",
      "20/20 - 0s - loss: 0.3049 - accuracy: 0.8901\n",
      "Epoch 28/130\n",
      "20/20 - 0s - loss: 0.3061 - accuracy: 0.8796\n",
      "Epoch 29/130\n",
      "20/20 - 0s - loss: 0.3020 - accuracy: 0.8848\n",
      "Epoch 30/130\n",
      "20/20 - 0s - loss: 0.3011 - accuracy: 0.8848\n",
      "Epoch 31/130\n",
      "20/20 - 0s - loss: 0.2994 - accuracy: 0.8848\n",
      "Epoch 32/130\n",
      "20/20 - 0s - loss: 0.2986 - accuracy: 0.8901\n",
      "Epoch 33/130\n",
      "20/20 - 0s - loss: 0.2963 - accuracy: 0.8848\n",
      "Epoch 34/130\n",
      "20/20 - 0s - loss: 0.2944 - accuracy: 0.8901\n",
      "Epoch 35/130\n",
      "20/20 - 0s - loss: 0.2941 - accuracy: 0.8953\n",
      "Epoch 36/130\n",
      "20/20 - 0s - loss: 0.2914 - accuracy: 0.8953\n",
      "Epoch 37/130\n",
      "20/20 - 0s - loss: 0.2910 - accuracy: 0.8953\n",
      "Epoch 38/130\n",
      "20/20 - 0s - loss: 0.2899 - accuracy: 0.8953\n",
      "Epoch 39/130\n",
      "20/20 - 0s - loss: 0.2870 - accuracy: 0.9005\n",
      "Epoch 40/130\n",
      "20/20 - 0s - loss: 0.2857 - accuracy: 0.8953\n",
      "Epoch 41/130\n",
      "20/20 - 0s - loss: 0.2843 - accuracy: 0.9005\n",
      "Epoch 42/130\n",
      "20/20 - 0s - loss: 0.2829 - accuracy: 0.9005\n",
      "Epoch 43/130\n",
      "20/20 - 0s - loss: 0.2814 - accuracy: 0.9005\n",
      "Epoch 44/130\n",
      "20/20 - 0s - loss: 0.2807 - accuracy: 0.9005\n",
      "Epoch 45/130\n",
      "20/20 - 0s - loss: 0.2793 - accuracy: 0.9005\n",
      "Epoch 46/130\n",
      "20/20 - 0s - loss: 0.2798 - accuracy: 0.9005\n",
      "Epoch 47/130\n",
      "20/20 - 0s - loss: 0.2783 - accuracy: 0.9005\n",
      "Epoch 48/130\n",
      "20/20 - 0s - loss: 0.2756 - accuracy: 0.8953\n",
      "Epoch 49/130\n",
      "20/20 - 0s - loss: 0.2744 - accuracy: 0.9005\n",
      "Epoch 50/130\n",
      "20/20 - 0s - loss: 0.2733 - accuracy: 0.9005\n",
      "Epoch 51/130\n",
      "20/20 - 0s - loss: 0.2714 - accuracy: 0.9005\n",
      "Epoch 52/130\n",
      "20/20 - 0s - loss: 0.2703 - accuracy: 0.9005\n",
      "Epoch 53/130\n",
      "20/20 - 0s - loss: 0.2678 - accuracy: 0.9005\n",
      "Epoch 54/130\n",
      "20/20 - 0s - loss: 0.2670 - accuracy: 0.9005\n",
      "Epoch 55/130\n",
      "20/20 - 0s - loss: 0.2662 - accuracy: 0.9005\n",
      "Epoch 56/130\n",
      "20/20 - 0s - loss: 0.2649 - accuracy: 0.9005\n",
      "Epoch 57/130\n",
      "20/20 - 0s - loss: 0.2675 - accuracy: 0.8953\n",
      "Epoch 58/130\n",
      "20/20 - 0s - loss: 0.2648 - accuracy: 0.9005\n",
      "Epoch 59/130\n",
      "20/20 - 0s - loss: 0.2614 - accuracy: 0.9005\n",
      "Epoch 60/130\n",
      "20/20 - 0s - loss: 0.2599 - accuracy: 0.9005\n",
      "Epoch 61/130\n",
      "20/20 - 0s - loss: 0.2584 - accuracy: 0.9005\n",
      "Epoch 62/130\n",
      "20/20 - 0s - loss: 0.2573 - accuracy: 0.9005\n",
      "Epoch 63/130\n",
      "20/20 - 0s - loss: 0.2562 - accuracy: 0.9005\n",
      "Epoch 64/130\n",
      "20/20 - 0s - loss: 0.2550 - accuracy: 0.9005\n",
      "Epoch 65/130\n",
      "20/20 - 0s - loss: 0.2560 - accuracy: 0.8953\n",
      "Epoch 66/130\n",
      "20/20 - 0s - loss: 0.2526 - accuracy: 0.9005\n",
      "Epoch 67/130\n",
      "20/20 - 0s - loss: 0.2509 - accuracy: 0.9005\n",
      "Epoch 68/130\n",
      "20/20 - 0s - loss: 0.2494 - accuracy: 0.9005\n",
      "Epoch 69/130\n",
      "20/20 - 0s - loss: 0.2510 - accuracy: 0.9005\n",
      "Epoch 70/130\n",
      "20/20 - 0s - loss: 0.2470 - accuracy: 0.9005\n",
      "Epoch 71/130\n",
      "20/20 - 0s - loss: 0.2472 - accuracy: 0.9005\n",
      "Epoch 72/130\n",
      "20/20 - 0s - loss: 0.2450 - accuracy: 0.9005\n",
      "Epoch 73/130\n",
      "20/20 - 0s - loss: 0.2433 - accuracy: 0.9005\n",
      "Epoch 74/130\n",
      "20/20 - 0s - loss: 0.2432 - accuracy: 0.9005\n",
      "Epoch 75/130\n",
      "20/20 - 0s - loss: 0.2407 - accuracy: 0.9005\n",
      "Epoch 76/130\n",
      "20/20 - 0s - loss: 0.2398 - accuracy: 0.9005\n",
      "Epoch 77/130\n",
      "20/20 - 0s - loss: 0.2382 - accuracy: 0.9005\n",
      "Epoch 78/130\n",
      "20/20 - 0s - loss: 0.2367 - accuracy: 0.9058\n",
      "Epoch 79/130\n",
      "20/20 - 0s - loss: 0.2374 - accuracy: 0.9058\n",
      "Epoch 80/130\n",
      "20/20 - 0s - loss: 0.2355 - accuracy: 0.9162\n",
      "Epoch 81/130\n",
      "20/20 - 0s - loss: 0.2346 - accuracy: 0.9110\n",
      "Epoch 82/130\n",
      "20/20 - 0s - loss: 0.2352 - accuracy: 0.9058\n",
      "Epoch 83/130\n",
      "20/20 - 0s - loss: 0.2317 - accuracy: 0.9110\n",
      "Epoch 84/130\n",
      "20/20 - 0s - loss: 0.2298 - accuracy: 0.9162\n",
      "Epoch 85/130\n",
      "20/20 - 0s - loss: 0.2283 - accuracy: 0.9162\n",
      "Epoch 86/130\n",
      "20/20 - 0s - loss: 0.2272 - accuracy: 0.9162\n",
      "Epoch 87/130\n",
      "20/20 - 0s - loss: 0.2268 - accuracy: 0.9162\n",
      "Epoch 88/130\n",
      "20/20 - 0s - loss: 0.2249 - accuracy: 0.9162\n",
      "Epoch 89/130\n",
      "20/20 - 0s - loss: 0.2232 - accuracy: 0.9162\n",
      "Epoch 90/130\n",
      "20/20 - 0s - loss: 0.2215 - accuracy: 0.9162\n",
      "Epoch 91/130\n",
      "20/20 - 0s - loss: 0.2202 - accuracy: 0.9162\n",
      "Epoch 92/130\n",
      "20/20 - 0s - loss: 0.2198 - accuracy: 0.9162\n",
      "Epoch 93/130\n",
      "20/20 - 0s - loss: 0.2182 - accuracy: 0.9162\n",
      "Epoch 94/130\n",
      "20/20 - 0s - loss: 0.2199 - accuracy: 0.9110\n",
      "Epoch 95/130\n",
      "20/20 - 0s - loss: 0.2151 - accuracy: 0.9162\n",
      "Epoch 96/130\n",
      "20/20 - 0s - loss: 0.2159 - accuracy: 0.9267\n",
      "Epoch 97/130\n",
      "20/20 - 0s - loss: 0.2154 - accuracy: 0.9162\n",
      "Epoch 98/130\n",
      "20/20 - 0s - loss: 0.2138 - accuracy: 0.9215\n",
      "Epoch 99/130\n",
      "20/20 - 0s - loss: 0.2128 - accuracy: 0.9215\n",
      "Epoch 100/130\n",
      "20/20 - 0s - loss: 0.2102 - accuracy: 0.9162\n",
      "Epoch 101/130\n",
      "20/20 - 0s - loss: 0.2090 - accuracy: 0.9162\n",
      "Epoch 102/130\n",
      "20/20 - 0s - loss: 0.2079 - accuracy: 0.9215\n",
      "Epoch 103/130\n",
      "20/20 - 0s - loss: 0.2076 - accuracy: 0.9162\n",
      "Epoch 104/130\n",
      "20/20 - 0s - loss: 0.2064 - accuracy: 0.9215\n",
      "Epoch 105/130\n",
      "20/20 - 0s - loss: 0.2091 - accuracy: 0.9215\n",
      "Epoch 106/130\n",
      "20/20 - 0s - loss: 0.2067 - accuracy: 0.9267\n",
      "Epoch 107/130\n",
      "20/20 - 0s - loss: 0.2059 - accuracy: 0.9215\n",
      "Epoch 108/130\n",
      "20/20 - 0s - loss: 0.2013 - accuracy: 0.9215\n",
      "Epoch 109/130\n",
      "20/20 - 0s - loss: 0.2013 - accuracy: 0.9215\n",
      "Epoch 110/130\n",
      "20/20 - 0s - loss: 0.1997 - accuracy: 0.9215\n",
      "Epoch 111/130\n",
      "20/20 - 0s - loss: 0.1990 - accuracy: 0.9215\n",
      "Epoch 112/130\n",
      "20/20 - 0s - loss: 0.1966 - accuracy: 0.9215\n",
      "Epoch 113/130\n",
      "20/20 - 0s - loss: 0.1955 - accuracy: 0.9215\n",
      "Epoch 114/130\n",
      "20/20 - 0s - loss: 0.1939 - accuracy: 0.9215\n",
      "Epoch 115/130\n",
      "20/20 - 0s - loss: 0.1934 - accuracy: 0.9215\n",
      "Epoch 116/130\n",
      "20/20 - 0s - loss: 0.1917 - accuracy: 0.9215\n",
      "Epoch 117/130\n",
      "20/20 - 0s - loss: 0.1909 - accuracy: 0.9215\n",
      "Epoch 118/130\n",
      "20/20 - 0s - loss: 0.1898 - accuracy: 0.9215\n",
      "Epoch 119/130\n",
      "20/20 - 0s - loss: 0.1893 - accuracy: 0.9215\n",
      "Epoch 120/130\n",
      "20/20 - 0s - loss: 0.1884 - accuracy: 0.9215\n",
      "Epoch 121/130\n",
      "20/20 - 0s - loss: 0.1866 - accuracy: 0.9267\n",
      "Epoch 122/130\n",
      "20/20 - 0s - loss: 0.1865 - accuracy: 0.9267\n",
      "Epoch 123/130\n",
      "20/20 - 0s - loss: 0.1852 - accuracy: 0.9372\n",
      "Epoch 124/130\n",
      "20/20 - 0s - loss: 0.1835 - accuracy: 0.9267\n",
      "Epoch 125/130\n",
      "20/20 - 0s - loss: 0.1825 - accuracy: 0.9319\n",
      "Epoch 126/130\n",
      "20/20 - 0s - loss: 0.1827 - accuracy: 0.9372\n",
      "Epoch 127/130\n",
      "20/20 - 0s - loss: 0.1805 - accuracy: 0.9372\n",
      "Epoch 128/130\n",
      "20/20 - 0s - loss: 0.1802 - accuracy: 0.9372\n",
      "Epoch 129/130\n",
      "20/20 - 0s - loss: 0.1785 - accuracy: 0.9372\n",
      "Epoch 130/130\n",
      "20/20 - 0s - loss: 0.1776 - accuracy: 0.9319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa54076e130>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X_train_enc, y_train_enc, epochs=130, batch_size=10, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "quick-spank",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.53\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_test_enc, y_test_enc, verbose=0)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-charge",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/how-to-prepare-categorical-data-for-deep-learning-in-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
